{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#I want to import from the parent directory\n",
    "sys.path.append('../src')\n",
    "import os\n",
    "from utils.path_utils import get_last_run_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"mlp\"   # mlp, lstm, cnn\n",
    "vocab_size = 0.1\n",
    "seed = 57\n",
    "dataset = \"FMereani.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "runs_folder = \"runs\"\n",
    "\n",
    "adv_folder = \"adversarial_agents\"\n",
    "det_folder = \"detectors\"\n",
    "vocab_file_name = \"vocabulary.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataset = \"src/prepare_dataset.py\"\n",
    "train_detector = \"src/train_detector.py\"\n",
    "train_adversarial_agent = \"src/train_adversarial_agent.py\"\n",
    "test_detector = \"src/test_detector.py\"\n",
    "test_adversarial_agent = \"src/test_adversarial_agent.py\"\n",
    "test_validity_mutated_dataset = \"src/test_validity_mutated_dataset.py\"\n",
    "analyze_validity = \"src/analyze_validity.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_folder = str(int(vocab_size * 100))\n",
    "vocab_file = os.path.join(data_folder, vocab_folder, vocab_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./serve_backend.sh\n"
     ]
    }
   ],
   "source": [
    "### Run Server\n",
    "command = \"./serve_backend.sh\"\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python src/prepare_dataset.py  --dataset data/FMereani.csv  --save_path data --seed 57 --vocab_size 0.1\n"
     ]
    }
   ],
   "source": [
    "### Prepare dataset\n",
    "command = f\"\"\"python {prepare_dataset} \n",
    "--dataset {os.path.join(data_folder, dataset)} \n",
    "--save_path {data_folder}\n",
    "--seed {seed}\n",
    "--vocab_size {vocab_size}\"\"\".strip()\n",
    "print(\" \".join(command.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python src/train_detector.py --trainset data/10/detectors/train.csv --valset data/10/detectors/val.csv --vocabulary data/10/vocabulary.csv --model lstm --seed 57\n"
     ]
    }
   ],
   "source": [
    "### Train detector\n",
    "command = f\"\"\"python {train_detector}\n",
    "--trainset {os.path.join(data_folder, vocab_folder,det_folder, \"train.csv\")}\n",
    "--valset {os.path.join(data_folder, vocab_folder,det_folder, \"val.csv\")}\n",
    "--vocabulary {os.path.join(data_folder, vocab_folder, vocab_file_name)}\n",
    "--model {model}\n",
    "--seed {seed}\n",
    "\"\"\".strip()\n",
    "print(\" \".join(command.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python src/test_detector.py --testset data/10/detectors/test.csv --vocab_file data/10/vocabulary.csv --model lstm --checkpoint_folder runs/lstm/10/run_0 --seed 57\n"
     ]
    }
   ],
   "source": [
    "### Test detector\n",
    "run_to_check = None\n",
    "if run_to_check is None:\n",
    "    last_run = get_last_run_number(os.path.join(\"../\"+runs_folder, model, vocab_folder))\n",
    "    run_to_check = os.path.join(runs_folder, model, vocab_folder, f\"run_{last_run}\")\n",
    "else:\n",
    "    run_to_check = os.path.join(runs_folder, model, vocab_folder, f\"run_{run_to_check}\")\n",
    "\n",
    "command = f\"\"\"python {test_detector}\n",
    "--testset {os.path.join(data_folder, vocab_folder, det_folder, \"test.csv\")}\n",
    "--vocab_file {os.path.join(data_folder, vocab_folder, vocab_file_name)}\n",
    "--model {model}\n",
    "--checkpoint_folder {run_to_check}\n",
    "--seed {seed}\"\"\".strip()\n",
    "print(\" \".join(command.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python src/train_adversarial_agent.py --trainset data/10/adversarial_agents/train.csv --valset data/10/adversarial_agents/val.csv --config_detector runs/lstm/10/run_0/config.json --seed 57\n"
     ]
    }
   ],
   "source": [
    "### Train adversarial agent\n",
    "command = f\"\"\"python {train_adversarial_agent}\n",
    "--trainset {os.path.join(data_folder, vocab_folder,adv_folder, \"train.csv\")}\n",
    "--valset {os.path.join(data_folder, vocab_folder,adv_folder, \"val.csv\")}\n",
    "--config_detector {os.path.join(run_to_check, \"config.json\")}\n",
    "--seed {seed}\"\"\".strip()\n",
    "print(\" \".join(command.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python src/test_adversarial_agent.py --testset data/10/adversarial_agents/test.csv --config_detector runs/lstm/10/run_0/config.json --checkpoint runs/lstm/10/run_0/adversarial_agent/run_2/best_model.zip --seed 57\n"
     ]
    }
   ],
   "source": [
    "### Test adversarial agent\n",
    "run_agent_to_check = None\n",
    "if run_agent_to_check is None:\n",
    "    last_run = get_last_run_number(os.path.join(\"../\"+run_to_check, \"adversarial_agent\"))\n",
    "    run_agent_to_check = os.path.join(run_to_check, \"adversarial_agent\", f\"run_{last_run}\")\n",
    "else:\n",
    "    run_agent_to_check = os.path.join(run_to_check, \"adversarial_agent\", f\"run_{run_agent_to_check}\")\n",
    "\n",
    "\n",
    "command = f\"\"\"python {test_adversarial_agent}\n",
    "--testset {os.path.join(data_folder, vocab_folder,adv_folder, \"test.csv\")}\n",
    "--config_detector {os.path.join(run_to_check, \"config.json\")}\n",
    "--checkpoint {os.path.join(run_agent_to_check, \"best_model.zip\")}\n",
    "--seed {seed}\"\"\".strip()\n",
    "print(\" \".join(command.splitlines()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python src/test_validity_mutated_dataset.py --dataset runs/lstm/10/run_0/adversarial_agent/run_2/empirical_study_set.csv --vocab data/10/vocabulary.csv --seed 57\n"
     ]
    }
   ],
   "source": [
    "### Test validity of mutated dataset\n",
    "command = f\"\"\"python {test_validity_mutated_dataset}\n",
    "--dataset {os.path.join(run_agent_to_check, \"empirical_study_set.csv\")}\n",
    "--vocab {os.path.join(data_folder, vocab_folder, vocab_file_name)}\n",
    "--seed {seed}\"\"\".strip()\n",
    "print(\" \".join(command.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python src/test_detector.py --testset runs/lstm/10/run_0/adversarial_agent/run_2/successes_test_set.csv --vocab_file data/10/vocabulary.csv --model lstm --checkpoint_folder runs/lstm/10/run_0 --test_file_name mutated_test_results.json --seed 57\n"
     ]
    }
   ],
   "source": [
    "### Test detectors against the mutated dataset\n",
    "command = f\"\"\"python {test_detector}\n",
    "--testset {os.path.join(run_agent_to_check, \"successes_test_set.csv\")}\n",
    "--vocab_file {os.path.join(data_folder, vocab_folder, vocab_file_name)}\n",
    "--model {model}\n",
    "--checkpoint_folder {run_to_check}\n",
    "--test_file_name mutated_test_results.json\n",
    "--seed {seed}\"\"\".strip()\n",
    "print(\" \".join(command.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python src/analyze_validity.py --dataset runs/lstm/10/run_0/adversarial_agent/run_2/validity.csv --seed 57\n"
     ]
    }
   ],
   "source": [
    "### Analyze validity\n",
    "command = f\"\"\"python {analyze_validity}\n",
    "--dataset {os.path.join(run_agent_to_check, \"validity.csv\")}\n",
    "--seed {seed}\"\"\".strip()\n",
    "print(\" \".join(command.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
